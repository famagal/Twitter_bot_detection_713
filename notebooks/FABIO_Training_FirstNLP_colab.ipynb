{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5q5T0PnkhTI"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers, Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BO1ZDldQoHTq",
        "outputId": "4294c050-be52-4424-d4a3-8be664b963ef"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tagx5iLyoU7t"
      },
      "source": [
        "data_path = '/content/drive/My Drive/Colab Notebooks/data/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf31PJAGnszM"
      },
      "source": [
        "df = pd.read_parquet(data_path + \"clean_text.parquet\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "hBEim6HYohNJ",
        "outputId": "99623131-5f08-4608-f33c-ee33bc537bc2"
      },
      "source": [
        "df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>best pate everhave searching taste since</td>\n",
              "      <td>human</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>pcc great examplereach elected official</td>\n",
              "      <td>human</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>theorem conclusion</td>\n",
              "      <td>human</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>theyre learning best</td>\n",
              "      <td>human</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>thread</td>\n",
              "      <td>human</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2353366</th>\n",
              "      <td>ruined everything goodalways said misunderstoo...</td>\n",
              "      <td>human</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2353367</th>\n",
              "      <td>every question</td>\n",
              "      <td>human</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2353369</th>\n",
              "      <td>song wish someone wrote pt</td>\n",
              "      <td>human</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2353371</th>\n",
              "      <td>song wish someone wrote pt</td>\n",
              "      <td>human</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2353372</th>\n",
              "      <td>behavioral research built every journey challe...</td>\n",
              "      <td>human</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1612980 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                clean_text target\n",
              "13                best pate everhave searching taste since  human\n",
              "14                 pcc great examplereach elected official  human\n",
              "15                                      theorem conclusion  human\n",
              "16                                    theyre learning best  human\n",
              "17                                                  thread  human\n",
              "...                                                    ...    ...\n",
              "2353366  ruined everything goodalways said misunderstoo...  human\n",
              "2353367                                     every question  human\n",
              "2353369                         song wish someone wrote pt  human\n",
              "2353371                         song wish someone wrote pt  human\n",
              "2353372  behavioral research built every journey challe...  human\n",
              "\n",
              "[1612980 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7Ho0lJVotHu"
      },
      "source": [
        "X = df.clean_text\n",
        "\n",
        "y = df['target'].map(lambda x: 1 if x == 'bot' else 0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1PEmyu7pP5O"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNmBo-BVpbtT"
      },
      "source": [
        "###transforming sentences in word sequences\n",
        "\n",
        "X_train = [text_to_word_sequence(i) for i in X_train]\n",
        "X_test = [text_to_word_sequence(i) for i in X_test]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiuPe9drpkaL"
      },
      "source": [
        "##Tokenizing\n",
        "\n",
        "tk = Tokenizer()\n",
        "\n",
        "tk.fit_on_texts(X_train)\n",
        "\n",
        "# We apply the tokenization to the train and test set\n",
        "X_train_token = tk.texts_to_sequences(X_train)\n",
        "X_test_token = tk.texts_to_sequences(X_test)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KU43HKvrpxwW",
        "outputId": "e1a6b49c-4100-4dfb-b83c-fe23367bdb37"
      },
      "source": [
        "vocab_size = len(tk.word_index)\n",
        "vocab_size"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "471139"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSO7R-a7p1uO"
      },
      "source": [
        "X_train_pad = pad_sequences(X_train_token, dtype='float32', padding='post', maxlen=25)\n",
        "X_test_pad = pad_sequences(X_test_token, dtype='float32', padding='post', maxlen=25)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DAxI1Aop7aY"
      },
      "source": [
        "embedding_size = 10\n",
        "\n",
        "def initialize_model():\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(layers.Embedding(input_dim=vocab_size+1,output_dim=embedding_size, mask_zero=True, input_length=25))\n",
        "    \n",
        "    model.add(layers.Conv1D(20, kernel_size=2))\n",
        "    \n",
        "    model.add(layers.Flatten())\n",
        "    \n",
        "    model.add(layers.Dense(10, activation='relu'))\n",
        "    \n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    \n",
        "  model.compile(loss='binary_crossentropy',\n",
        "                 optimizer='adam',\n",
        "                 metrics=['accuracy','Precision','Recall']\n",
        "                 )\n",
        "    return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsvQ7JiqqAYb",
        "outputId": "27c74558-79f7-4b47-8947-cf40b5a02b29"
      },
      "source": [
        "cnn = initialize_model()\n",
        "\n",
        "cnn.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 25, 10)            4711400   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 24, 20)            420       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 480)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                4810      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,716,641\n",
            "Trainable params: 4,716,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEjDUkUYqCoF",
        "outputId": "0cc255cf-cd21-4408-9c2e-c13e950f10d2"
      },
      "source": [
        "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
        "\n",
        "history = cnn.fit(X_train_pad, y_train, \n",
        "          epochs=500, \n",
        "          batch_size=32,\n",
        "          validation_split=0.3,\n",
        "          callbacks=[es]\n",
        "         )"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "28228/28228 [==============================] - 426s 15ms/step - loss: 0.3269 - accuracy: 0.8875 - precision: 0.8170 - recall: 0.2139 - val_loss: 0.3072 - val_accuracy: 0.8958 - val_precision: 0.8285 - val_recall: 0.2832\n",
            "Epoch 2/500\n",
            "28228/28228 [==============================] - 377s 13ms/step - loss: 0.2739 - accuracy: 0.9066 - precision: 0.8471 - recall: 0.3759 - val_loss: 0.3067 - val_accuracy: 0.8976 - val_precision: 0.7870 - val_recall: 0.3267\n",
            "Epoch 3/500\n",
            "28228/28228 [==============================] - 379s 13ms/step - loss: 0.2362 - accuracy: 0.9200 - precision: 0.8719 - recall: 0.4768 - val_loss: 0.3371 - val_accuracy: 0.8832 - val_precision: 0.5995 - val_recall: 0.3945\n",
            "Epoch 4/500\n",
            "28228/28228 [==============================] - 374s 13ms/step - loss: 0.2094 - accuracy: 0.9299 - precision: 0.8938 - recall: 0.5448 - val_loss: 0.3489 - val_accuracy: 0.8859 - val_precision: 0.6263 - val_recall: 0.3735\n",
            "Epoch 5/500\n",
            "28228/28228 [==============================] - 375s 13ms/step - loss: 0.1914 - accuracy: 0.9361 - precision: 0.9071 - recall: 0.5863 - val_loss: 0.3811 - val_accuracy: 0.8746 - val_precision: 0.5455 - val_recall: 0.4007\n",
            "Epoch 6/500\n",
            "28228/28228 [==============================] - 376s 13ms/step - loss: 0.1791 - accuracy: 0.9403 - precision: 0.9185 - recall: 0.6121 - val_loss: 0.4011 - val_accuracy: 0.8711 - val_precision: 0.5268 - val_recall: 0.4037\n",
            "Epoch 7/500\n",
            "28228/28228 [==============================] - 379s 13ms/step - loss: 0.1702 - accuracy: 0.9437 - precision: 0.9230 - recall: 0.6360 - val_loss: 0.4254 - val_accuracy: 0.8653 - val_precision: 0.4984 - val_recall: 0.4132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tk5CfMFz1RHA",
        "outputId": "3f126360-af17-42a6-ba39-837bd361b616"
      },
      "source": [
        "cnn.evaluate(X_test_pad,y_test)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10082/10082 [==============================] - 52s 5ms/step - loss: 0.3069 - accuracy: 0.8982 - precision: 0.8211 - recall: 0.3130\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.306924045085907, 0.8982380628585815, 0.8210945725440979, 0.3130362629890442]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}