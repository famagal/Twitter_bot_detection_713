{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb8533ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "from Twitter_bot_detection_713.data_prep import get_final_tweet_data\n",
    "from Twitter_bot_detection_713.preprocessing_text import apply_text_cleaning\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f70b39",
   "metadata": {},
   "source": [
    "# Loading and Cleaning dataset text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43dfa3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_final_tweet_data(en=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d30a3da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = apply_text_cleaning(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6addd74c",
   "metadata": {},
   "source": [
    "# Vectorization of clean text -Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caf2b9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizing 1\n",
      "vectorizing 2\n",
      "fixing target\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "##X_bow will be bag of words and X_bow2 will be Tfidf\n",
    "\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "\n",
    "tf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "\n",
    "print('vectorizing 1')\n",
    "\n",
    "X_bow = count_vectorizer.fit_transform(df['clean_text'])\n",
    "\n",
    "print('vectorizing 2')\n",
    "\n",
    "X_bow2 = tf_vectorizer.fit_transform(df['clean_text'])\n",
    "\n",
    "print('fixing target')\n",
    "\n",
    "y = df['target'].map(lambda x: 1 if x == 'bot' else 0)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ae0d14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##cross-validating models\n",
    "\n",
    "nb = MultinomialNB()\n",
    "\n",
    "\n",
    "cv1 = cross_validate(nb, X_bow, y, scoring=['accuracy','precision','recall','f1'], cv=5)\n",
    "cv2 = cross_validate(nb, X_bow2, y, scoring=['accuracy','precision','recall','f1'], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac1ef8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.17521954, 0.98704123, 1.2582972 , 1.22636294, 1.09254098]),\n",
       " 'score_time': array([0.42981291, 0.46502376, 0.54167247, 0.50081849, 0.46874166]),\n",
       " 'test_accuracy': array([0.85215254, 0.85619784, 0.85521519, 0.85007254, 0.85221453]),\n",
       " 'test_precision': array([0.38801379, 0.42221985, 0.42280886, 0.37603243, 0.40504384]),\n",
       " 'test_recall': array([0.16829223, 0.18218623, 0.20373565, 0.17070366, 0.20615094]),\n",
       " 'test_f1': array([0.23476182, 0.25453961, 0.27497245, 0.23481205, 0.27323587])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36e5367f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.11444449, 1.18323612, 1.53567791, 1.42631435, 1.41693997]),\n",
       " 'score_time': array([0.45593905, 0.41108513, 0.44546652, 0.47043848, 0.46181417]),\n",
       " 'test_accuracy': array([0.86912423, 0.87145532, 0.87298665, 0.87121353, 0.86749061]),\n",
       " 'test_precision': array([0.89027431, 0.94852283, 0.9486535 , 0.95426686, 0.88535032]),\n",
       " 'test_recall': array([0.03284873, 0.04874402, 0.06077335, 0.04655763, 0.01918432]),\n",
       " 'test_f1': array([0.06335966, 0.09272306, 0.11422889, 0.08878361, 0.03755488])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbe29566",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Holdout\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_bow, y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_bow2, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88ee937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###fitting model with bag of words\n",
    "\n",
    "nb = MultinomialNB()\n",
    "model = nb.fit(X_train1,y_train1)\n",
    "\n",
    "model2 = nb.fit(X_train2,y_train2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c07fea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "y_pred1 = model.predict(X_test1)\n",
    "y_pred2 = model2.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0856a5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision model 1: 0.9774676551824393\n",
      "recall model 1: 0.154773961881963\n",
      "f1 model 1: 0.2672336704886434\n",
      "     \n",
      "precision model 2: 0.9890774659721056\n",
      "recall model 2: 0.13548476199245005\n",
      "f1 model 2: 0.23832371697540236\n"
     ]
    }
   ],
   "source": [
    "###Model results\n",
    "\n",
    "\n",
    "print(f'precision model 1: {precision_score(y_test1, y_pred1)}')\n",
    "print(f'recall model 1: {recall_score(y_test1, y_pred1)}')\n",
    "print(f'f1 model 1: {f1_score(y_test1, y_pred1)}')\n",
    "\n",
    "\n",
    "print('     ')\n",
    "\n",
    "print(f'precision model 2: {precision_score(y_test2, y_pred2)}')\n",
    "print(f'recall model 2: {recall_score(y_test2, y_pred2)}')\n",
    "print(f'f1 model 2: {f1_score(y_test2, y_pred2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c63a10",
   "metadata": {},
   "source": [
    "# RNN testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b22a6f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-25 21:55:25.209334: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-25 21:55:25.209419: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e69cac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.clean_text\n",
    "\n",
    "y = df['target'].map(lambda x: 1 if x == 'bot' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c72dce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12bc257b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###transforming sentences in word sequences\n",
    "\n",
    "X_train = [text_to_word_sequence(i) for i in X_train]\n",
    "X_test = [text_to_word_sequence(i) for i in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "05e293d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['perfect',\n",
       " 'interest',\n",
       " 'cotton',\n",
       " 'crop',\n",
       " 'yield',\n",
       " 'heavy',\n",
       " 'reniform',\n",
       " 'nematode',\n",
       " 'ground']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce17037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Tokenizing\n",
    "\n",
    "tk = Tokenizer()\n",
    "\n",
    "tk.fit_on_texts(X_train)\n",
    "\n",
    "# We apply the tokenization to the train and test set\n",
    "X_train_token = tk.texts_to_sequences(X_train)\n",
    "X_test_token = tk.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3db30610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1290384"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33bf8353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "471139"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tk.word_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ca922bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.27893e+05, 3.62958e+05, 1.57041e+05, 1.00351e+05, 3.88840e+04,\n",
       "        3.11400e+03, 1.31000e+02, 1.00000e+01, 1.00000e+00, 1.00000e+00]),\n",
       " array([ 0. ,  6.1, 12.2, 18.3, 24.4, 30.5, 36.6, 42.7, 48.8, 54.9, 61. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###Padding - checking for how to pad\n",
    "\n",
    "list_len_Xt = [len(i) for i in X_train]\n",
    "plt.hist(list_len_Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56ecfd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pad = pad_sequences(X_train_token, dtype='float32', padding='post', maxlen=25)\n",
    "X_test_pad = pad_sequences(X_test_token, dtype='float32', padding='post', maxlen=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "faae39fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 10\n",
    "\n",
    "def initialize_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(layers.Embedding(input_dim=vocab_size+1,output_dim=embedding_size, mask_zero=True, input_length=25))\n",
    "    \n",
    "    model.add(layers.LSTM(20))\n",
    "    \n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    \n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer='adam',\n",
    "                  metrics=['accuracy','Precision','Recall']\n",
    "                 )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8d5021e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-25 22:05:24.137165: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-11-25 22:05:24.137210: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-25 22:05:24.137226: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-K2LUF1RF): /proc/driver/nvidia/version does not exist\n",
      "2021-11-25 22:05:24.137564: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 25, 10)            4711400   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 20)                2480      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 4,714,101\n",
      "Trainable params: 4,714,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn = initialize_model()\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1022f25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-25 16:09:32.294103: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "28228/28228 [==============================] - 468s 17ms/step - loss: 0.3254 - accuracy: 0.8880 - precision: 0.8104 - recall: 0.2218 - val_loss: 0.3047 - val_accuracy: 0.8970 - val_precision: 0.8632 - val_recall: 0.2777\n",
      "Epoch 2/500\n",
      "15502/28228 [===============>..............] - ETA: 3:15 - loss: 0.2689 - accuracy: 0.9084 - precision: 0.8537 - recall: 0.3875"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qr/rfdswcsx19d9ymx44xfqyk5m0000gn/T/ipykernel_37394/1253915688.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m history = cnn.fit(X_train_pad, y_train, \n\u001b[0m\u001b[1;32m      4\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###Model architecture works, but it would take ages to complete. Will export files to colab and try to run the model there\n",
    "\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "history = cnn.fit(X_train_pad, y_train, \n",
    "          epochs=500, \n",
    "          batch_size=64,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[es]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "191f7cdd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowNotImplementedError",
     "evalue": "Unhandled type for Arrow to Parquet schema conversion: duration[ns]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowNotImplementedError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qr/rfdswcsx19d9ymx44xfqyk5m0000gn/T/ipykernel_37394/10192738.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mparquet_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_final_tweet_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mapply_text_cleaning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparquet_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_to_parquet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/famagal/Twitter_bot_detection_713/Twitter_bot_detection_713/preprocessing_text.py\u001b[0m in \u001b[0;36mapply_text_cleaning\u001b[0;34m(df, write_to_parquet)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrite_to_parquet\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Twitter_bot_detection_713/data/clean_text_df.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_parquet\u001b[0;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m   2675\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_parquet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2677\u001b[0;31m         return to_parquet(\n\u001b[0m\u001b[1;32m   2678\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2679\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mto_parquet\u001b[0;34m(df, path, engine, compression, index, storage_options, partition_cols, **kwargs)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFilePathOrBuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m     impl.write(\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, df, path, compression, index, storage_options, partition_cols, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0;31m# write to single output file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m                 self.api.parquet.write_table(\n\u001b[0m\u001b[1;32m    195\u001b[0m                     \u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 )\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/pyarrow/parquet.py\u001b[0m in \u001b[0;36mwrite_table\u001b[0;34m(table, where, row_group_size, version, use_dictionary, compression, write_statistics, use_deprecated_int96_timestamps, coerce_timestamps, allow_truncated_timestamps, data_page_size, flavor, filesystem, compression_level, use_byte_stream_split, data_page_version, use_compliant_nested_type, **kwargs)\u001b[0m\n\u001b[1;32m   2015\u001b[0m     \u001b[0muse_int96\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_deprecated_int96_timestamps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2016\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2017\u001b[0;31m         with ParquetWriter(\n\u001b[0m\u001b[1;32m   2018\u001b[0m                 \u001b[0mwhere\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2019\u001b[0m                 \u001b[0mfilesystem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilesystem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/pyarrow/parquet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, where, schema, filesystem, flavor, version, use_dictionary, compression, write_statistics, use_deprecated_int96_timestamps, compression_level, use_byte_stream_split, writer_engine_version, data_page_version, use_compliant_nested_type, **options)\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata_collector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'metadata_collector'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0mengine_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'V2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m         self.writer = _parquet.ParquetWriter(\n\u001b[0m\u001b[1;32m    664\u001b[0m             \u001b[0msink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/pyarrow/_parquet.pyx\u001b[0m in \u001b[0;36mpyarrow._parquet.ParquetWriter.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowNotImplementedError\u001b[0m: Unhandled type for Arrow to Parquet schema conversion: duration[ns]"
     ]
    }
   ],
   "source": [
    "##writing df with clean text to parquet\n",
    "\n",
    "parquet_df = get_final_tweet_data(en=True)\n",
    "apply_text_cleaning(parquet_df, write_to_parquet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "482418eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lag</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>reply_category</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>n_mentions</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1000197919</td>\n",
       "      <td>1261733558474829824</td>\n",
       "      <td>en</td>\n",
       "      <td>@trekonomics Same here. Best pate ever....have...</td>\n",
       "      <td>2020-05-16 19:01:36+00:00</td>\n",
       "      <td>33 days 14:13:11</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Reply_to_other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>human</td>\n",
       "      <td>best pate everhave searching taste since</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1000197919</td>\n",
       "      <td>1264695397588406272</td>\n",
       "      <td>en</td>\n",
       "      <td>PCC is a great example....reach out to your el...</td>\n",
       "      <td>2020-05-24 23:10:54+00:00</td>\n",
       "      <td>8 days 04:09:18</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>No_reply</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>pcc great examplereach elected official</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1000197919</td>\n",
       "      <td>1271119064941752320</td>\n",
       "      <td>en</td>\n",
       "      <td>both the theorem - and the conclusion. https:/...</td>\n",
       "      <td>2020-06-11 16:36:15+00:00</td>\n",
       "      <td>17 days 17:25:21</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>No_reply</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>theorem conclusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1000197919</td>\n",
       "      <td>1273846820133695488</td>\n",
       "      <td>en</td>\n",
       "      <td>@GeneralCattis they're learning from the best!</td>\n",
       "      <td>2020-06-19 05:15:23+00:00</td>\n",
       "      <td>7 days 12:39:08</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Reply_to_other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>human</td>\n",
       "      <td>theyre learning best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1000197919</td>\n",
       "      <td>1275472007769976832</td>\n",
       "      <td>en</td>\n",
       "      <td>this thread... https://t.co/OSveBlPctt</td>\n",
       "      <td>2020-06-23 16:53:18+00:00</td>\n",
       "      <td>4 days 11:37:55</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>No_reply</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>thread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2353366</th>\n",
       "      <td>999977095106367488</td>\n",
       "      <td>1426676881638793216</td>\n",
       "      <td>en</td>\n",
       "      <td>you ruined everything good\\nalways said you we...</td>\n",
       "      <td>2021-08-14 22:47:29+00:00</td>\n",
       "      <td>0 days 13:31:13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>No_reply</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>ruined everything goodalways said misunderstoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2353367</th>\n",
       "      <td>999977095106367488</td>\n",
       "      <td>1427777414088777728</td>\n",
       "      <td>en</td>\n",
       "      <td>for every question why \\nyou were my because</td>\n",
       "      <td>2021-08-17 23:40:36+00:00</td>\n",
       "      <td>3 days 00:53:07</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>No_reply</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>every question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2353369</th>\n",
       "      <td>999977095106367488</td>\n",
       "      <td>1431950553173659648</td>\n",
       "      <td>en</td>\n",
       "      <td>song i wish someone wrote for me pt1: https://...</td>\n",
       "      <td>2021-08-29 12:03:10+00:00</td>\n",
       "      <td>8 days 15:31:58</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>No_reply</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>song wish someone wrote pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2353371</th>\n",
       "      <td>999977095106367488</td>\n",
       "      <td>1435588625811611648</td>\n",
       "      <td>en</td>\n",
       "      <td>song i wish someone wrote for me pt2: https://...</td>\n",
       "      <td>2021-09-08 12:59:34+00:00</td>\n",
       "      <td>5 days 03:18:45</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>No_reply</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>song wish someone wrote pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2353372</th>\n",
       "      <td>999977095106367488</td>\n",
       "      <td>1436375696033697835</td>\n",
       "      <td>en</td>\n",
       "      <td>Behavioral research is built into every journe...</td>\n",
       "      <td>2021-09-10 17:07:07+00:00</td>\n",
       "      <td>2 days 04:07:33</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>No_reply</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>human</td>\n",
       "      <td>behavioral research built every journey challe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1612980 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  author_id                   id lang  \\\n",
       "13               1000197919  1261733558474829824   en   \n",
       "14               1000197919  1264695397588406272   en   \n",
       "15               1000197919  1271119064941752320   en   \n",
       "16               1000197919  1273846820133695488   en   \n",
       "17               1000197919  1275472007769976832   en   \n",
       "...                     ...                  ...  ...   \n",
       "2353366  999977095106367488  1426676881638793216   en   \n",
       "2353367  999977095106367488  1427777414088777728   en   \n",
       "2353369  999977095106367488  1431950553173659648   en   \n",
       "2353371  999977095106367488  1435588625811611648   en   \n",
       "2353372  999977095106367488  1436375696033697835   en   \n",
       "\n",
       "                                                      text  \\\n",
       "13       @trekonomics Same here. Best pate ever....have...   \n",
       "14       PCC is a great example....reach out to your el...   \n",
       "15       both the theorem - and the conclusion. https:/...   \n",
       "16          @GeneralCattis they're learning from the best!   \n",
       "17                  this thread... https://t.co/OSveBlPctt   \n",
       "...                                                    ...   \n",
       "2353366  you ruined everything good\\nalways said you we...   \n",
       "2353367       for every question why \\nyou were my because   \n",
       "2353369  song i wish someone wrote for me pt1: https://...   \n",
       "2353371  song i wish someone wrote for me pt2: https://...   \n",
       "2353372  Behavioral research is built into every journe...   \n",
       "\n",
       "                       created_at              lag  possibly_sensitive  \\\n",
       "13      2020-05-16 19:01:36+00:00 33 days 14:13:11               False   \n",
       "14      2020-05-24 23:10:54+00:00  8 days 04:09:18               False   \n",
       "15      2020-06-11 16:36:15+00:00 17 days 17:25:21               False   \n",
       "16      2020-06-19 05:15:23+00:00  7 days 12:39:08               False   \n",
       "17      2020-06-23 16:53:18+00:00  4 days 11:37:55               False   \n",
       "...                           ...              ...                 ...   \n",
       "2353366 2021-08-14 22:47:29+00:00  0 days 13:31:13               False   \n",
       "2353367 2021-08-17 23:40:36+00:00  3 days 00:53:07               False   \n",
       "2353369 2021-08-29 12:03:10+00:00  8 days 15:31:58               False   \n",
       "2353371 2021-09-08 12:59:34+00:00  5 days 03:18:45               False   \n",
       "2353372 2021-09-10 17:07:07+00:00  2 days 04:07:33               False   \n",
       "\n",
       "         referenced_tweets  reply_category  like_count  quote_count  \\\n",
       "13                    True  Reply_to_other           0            0   \n",
       "14                    True        No_reply           0            0   \n",
       "15                    True        No_reply           0            0   \n",
       "16                    True  Reply_to_other           0            0   \n",
       "17                    True        No_reply           0            0   \n",
       "...                    ...             ...         ...          ...   \n",
       "2353366              False        No_reply           0            0   \n",
       "2353367              False        No_reply           0            0   \n",
       "2353369              False        No_reply           0            0   \n",
       "2353371              False        No_reply           0            0   \n",
       "2353372              False        No_reply           0            0   \n",
       "\n",
       "         reply_count  retweet_count  n_mentions target  \\\n",
       "13                 0              0           1  human   \n",
       "14                 0              0           0  human   \n",
       "15                 0              0           0  human   \n",
       "16                 0              0           1  human   \n",
       "17                 0              0           0  human   \n",
       "...              ...            ...         ...    ...   \n",
       "2353366            0              0           0  human   \n",
       "2353367            0              0           0  human   \n",
       "2353369            0              0           0  human   \n",
       "2353371            0              0           0  human   \n",
       "2353372            0              0           0  human   \n",
       "\n",
       "                                                clean_text  \n",
       "13                best pate everhave searching taste since  \n",
       "14                 pcc great examplereach elected official  \n",
       "15                                      theorem conclusion  \n",
       "16                                    theyre learning best  \n",
       "17                                                  thread  \n",
       "...                                                    ...  \n",
       "2353366  ruined everything goodalways said misunderstoo...  \n",
       "2353367                                     every question  \n",
       "2353369                         song wish someone wrote pt  \n",
       "2353371                         song wish someone wrote pt  \n",
       "2353372  behavioral research built every journey challe...  \n",
       "\n",
       "[1612980 rows x 16 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_text_cleaning(parquet_df, write_to_parquet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d1afdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['clean_text', 'target']].to_parquet('../Twitter_bot_detection_713/data/clean_text.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65adfae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
